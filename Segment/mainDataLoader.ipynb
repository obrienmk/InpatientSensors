{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing required libraries, and initializing workspace variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-04T21:48:51.029163Z",
     "start_time": "2019-06-04T21:48:41.122614Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add libraries when required if adapting base script\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask\n",
    "import dask.delayed as ddel\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client\n",
    "import datetime as dt\n",
    "import scipy.io as sio\n",
    "import collections\n",
    "import time\n",
    "import copy\n",
    "import datetime\n",
    "# from datetime import datetime\n",
    "from pytz import timezone\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -----------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read annotations and cut file raw datafile into chuncks acording to each activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-04T21:48:51.063102Z",
     "start_time": "2019-06-04T21:48:51.031049Z"
    }
   },
   "outputs": [],
   "source": [
    "def readAnnotationsFile(path, activitySet):\n",
    "\n",
    "    '''\n",
    "    Debug section\n",
    "    '''\n",
    "#     path = r'//FS2.smpp.local\\RTO\\Inpatient Sensors -Stroke\\MC10 Study\\Data\\biostamp_data\\cva\\CVA08\\bicep_left\\d5la7xyp\\2018-05-31T20-22-51-653Z\\accel.csv'\n",
    "#     activitySet = [\n",
    "#             'Clinical - 10MWT SSV', 'Clinical - 10MWT FV', 'Activity Recognition',\n",
    "#             'Resting ECG', 'Physical Therapy', 'Clinical - TUG',\n",
    "#             'Clinical - MAS', 'Clinical - MMT', 'Clinical - 6MWT',\n",
    "#             'Clinical - BBS'\n",
    "#                   ]\n",
    "#     activitySet = ['Clinical - 10MWT SSV']\n",
    "#     currentPath = r'//FS2.smpp.local\\RTO\\Inpatient Sensors -Stroke\\MC10 Study\\Data\\biostamp_data\\cva\\CVA08'\n",
    "    '''\n",
    "    End debug section\n",
    "    '''\n",
    "\n",
    "    # Read the .csv file (path) that was given as an argument in the 'extractSubjectData' function\n",
    "    dfRaw = pd.read_csv(path)\n",
    "    # ... and remove duplicate timestamps if present in this datafile\n",
    "    dfRaw = dfRaw.drop_duplicates(subset=dfRaw.columns[0], keep='first').reset_index(drop=True)\n",
    "\n",
    "    # Find the annotation file in the current subject directory (global variable 'currentPath')\n",
    "    dfAnnotations = pd.read_csv(os.path.join(currentPath, 'annotations.csv'))\n",
    "\n",
    "    # Delete unwanted collumns (for debugging purposes, not really required for running the script)\n",
    "    del dfAnnotations['Timestamp (ms)']\n",
    "    del dfAnnotations['AnnotationId']\n",
    "    del dfAnnotations['AuthorId']\n",
    "\n",
    "    # Iterate over all the activities present in the activitySet\n",
    "    for entries in range(len(activitySet)):\n",
    "        # If this is the first entry of the activitySet, preallocate the function output variable\n",
    "        if entries == 0:\n",
    "            activityData = {}\n",
    "\n",
    "        # Python variables are always linked, so instead if we make a (shallow) copy of the variable. Now we can alter the \n",
    "        # annotations file\n",
    "        df = dfAnnotations.copy()\n",
    "\n",
    "        # Extract the current activityName\n",
    "        activityName = activitySet[entries]\n",
    "\n",
    "        # For now, we construct an activity dataframe seperately for each activity. Since activities differ in the way they are\n",
    "        # written in the annotations file, we 1) detect the event type and 2) sort the associated value as follows:\n",
    "        activityAnnotationSet = df[df['EventType'].str.match(activityName)]\n",
    "        activityAnnotationSet = activityAnnotationSet.drop_duplicates(subset=activityAnnotationSet.columns[1:2], keep='first')\n",
    "\n",
    "        # If the previously formed activitySet is empty (the activity wasn't present in the annotations file), continue to\n",
    "        # the next activity in the activitySet\n",
    "        if activityAnnotationSet.empty:\n",
    "            activityData[activityName] = {}\n",
    "            continue\n",
    "\n",
    "        # Starting with these 4:\n",
    "        if (\n",
    "            activityName == 'Activity Recognition' or \n",
    "            activityName == 'Resting ECG' or\n",
    "            activityName == 'Physical Therapy' or\n",
    "            activityName == 'Clinical - BBS'\n",
    "           ):\n",
    "\n",
    "            # Preallocate the dataframe:\n",
    "            eventTypeSetComp = pd.DataFrame()\n",
    "\n",
    "            # Iterate over all the event types:\n",
    "            for ran in range(0,len(activityAnnotationSet)):\n",
    "                tt = df[df['Stop Timestamp (ms)'] == activityAnnotationSet['Stop Timestamp (ms)'][activityAnnotationSet.index[ran]]]\n",
    "                tt = tt.sort_values(by=['Start Timestamp (ms)'])\n",
    "                if activityName == 'Activity Recognition':\n",
    "                    eventTypeSet = tt[tt['EventType'].str.match('Activity type')]\n",
    "                elif activityName == 'Resting ECG':\n",
    "                    eventTypeSet = tt[tt['EventType'].str.match('When was rest performed?')]; \n",
    "                elif activityName == 'Physical Therapy':\n",
    "                    eventTypeSet = tt[tt['EventType'].str.match('Type of Physical Therapy')]; \n",
    "                elif activityName == 'Clinical - BBS':\n",
    "                    eventTypeSet = tt[tt['EventType'].str.match('Type of Assessment')]; \n",
    "                eventTypeSetComp = eventTypeSetComp.append(eventTypeSet)\n",
    "                eventTypeSetComp = eventTypeSetComp.drop_duplicates(subset=eventTypeSetComp.columns[1:2], keep='first')\n",
    "            activityAnnotationSet.Value = eventTypeSetComp.Value.values\n",
    "\n",
    "        # If not the first 4, then:\n",
    "        elif (\n",
    "            activityName == 'Clinical - MAS' or\n",
    "            activityName == 'Clinical - MMT'\n",
    "           ): \n",
    "\n",
    "            # Preallocate the dataframe:\n",
    "            eventTypeSetComp = pd.DataFrame()\n",
    "            sideSetComp = pd.DataFrame()\n",
    "\n",
    "            # Iterate over all the event types:\n",
    "            for ran in range(0,len(activityAnnotationSet)):\n",
    "                tt = df[df['Stop Timestamp (ms)'] == activityAnnotationSet['Stop Timestamp (ms)'][activityAnnotationSet.index[ran]]]\n",
    "                tt = tt.drop_duplicates(subset=tt.columns[0], keep='first')\n",
    "                tt = tt.sort_values(by=['Start Timestamp (ms)'])\n",
    "                if activityName == 'Clinical - MAS':\n",
    "                    eventTypeSet = tt[tt['EventType'].str.match('Movement Type')] \n",
    "                elif activityName == 'Clinical - MMT':\n",
    "                    eventTypeSet = tt[tt['EventType'].str.match('Type of Activity')]\n",
    "                sideSet = tt[tt['EventType'].str.match('Side')]\n",
    "                eventTypeSetComp = eventTypeSetComp.append(eventTypeSet)\n",
    "                eventTypeSetComp = eventTypeSetComp.drop_duplicates(subset=eventTypeSetComp.columns[1:2], keep='first')\n",
    "                sideSetComp = sideSetComp.append(sideSet)\n",
    "            activityAnnotationSet.Value = sideSetComp.Value.values + '_' + eventTypeSetComp.Value.values\n",
    "\n",
    "        # Here we create a readable dataframe, again for debugging purposes only\n",
    "        activityAnnotationSet['Session'] = activityAnnotationSet.groupby('EventType')['Start Timestamp (ms)'].rank(ascending=True).astype(int)\n",
    "        activityAnnotationSet = activityAnnotationSet.reset_index(drop=True).set_index('Session')\n",
    "        activityAnnotationSet.insert(0,'date',pd.to_datetime(activityAnnotationSet['Start Timestamp (ms)'], unit='ms'))\n",
    "        activityAnnotationSet.date = activityAnnotationSet.date.dt.date\n",
    "        del activityAnnotationSet['EventType']    \n",
    "\n",
    "         # Create easily accesible matrix of start-and endtimes\n",
    "        startSize = len(activityAnnotationSet.index)\n",
    "        if startSize == 1:\n",
    "            startTimestamp = pd.Series(activityAnnotationSet.loc[1, 'Start Timestamp (ms)'])\n",
    "            endTimestamp = pd.Series(activityAnnotationSet.loc[1, 'Stop Timestamp (ms)'])\n",
    "        else:\n",
    "            startTimestamp = pd.Series(activityAnnotationSet.loc[1:startSize, 'Start Timestamp (ms)'].values)\n",
    "            endTimestamp = pd.Series(activityAnnotationSet.loc[1:startSize, 'Stop Timestamp (ms)'].values)\n",
    "\n",
    "        # Small check/ correction to change if the activityType string starts with a number (Matlab doesn't accept variables\n",
    "        # starting with a number)\n",
    "        if pd.isnull(activityAnnotationSet.iloc[0,3]):\n",
    "            pass\n",
    "        else:\n",
    "            for nTrials in range(0, len(activityAnnotationSet['Value'])):\n",
    "                if activityAnnotationSet.iloc[nTrials,3][0:2].isdigit():\n",
    "                    activityAnnotationSet.iloc[nTrials,3] = activityAnnotationSet.iloc[nTrials,3].replace(activityAnnotationSet.iloc[nTrials,3][0:2], 'N' + str(activityAnnotationSet.iloc[nTrials,3][0:2]))\n",
    "                elif activityAnnotationSet.iloc[nTrials,3][0:1].isdigit():\n",
    "                    activityAnnotationSet.iloc[nTrials,3] = activityAnnotationSet.iloc[nTrials,3].replace(activityAnnotationSet.iloc[nTrials,3][0:1], 'N' + str(activityAnnotationSet.iloc[nTrials,3][0:1]))\n",
    "\n",
    "        # Created nested dictionary containing number of occurrences of all trials of given activity entry\n",
    "        occOfTrials = Counter(activityAnnotationSet['Value'])\n",
    "        occOfTrialsTBD = dict(occOfTrials.copy())\n",
    "\n",
    "        # For the amount of trials of this eventtype (for example; 2 trials of 10MWT etc.), slice the raw data and save it\n",
    "        # as a filled dataframe\n",
    "        for trials in range(0, np.size(startTimestamp)):\n",
    "\n",
    "            # If this is the first trial of the given activity, preallocate some variables\n",
    "            if trials == 0:\n",
    "                fild_df = {}\n",
    "                triCount = 1\n",
    "\n",
    "            # Here we select data of the raw datafiles that start and end on the timestamps as given by the annotation file\n",
    "            act1_df = dfRaw[(dfRaw['Timestamp (ms)'] >= startTimestamp[trials]) & (dfRaw['Timestamp (ms)'] <= endTimestamp[trials])]\n",
    "\n",
    "            # Resample selected data to correct faulty timestamp series\n",
    "            if act1_df.empty:\n",
    "                continue\n",
    "            else:\n",
    "                tt = act1_df.copy()\n",
    "                tt['Timestamp (ms)'] = pd.to_datetime(tt['Timestamp (ms)'],unit='ms')\n",
    "\n",
    "                if os.path.basename(path).startswith('accel') or os.path.basename(path).startswith('gyro'):\n",
    "                    tt = tt.resample('32ms', on='Timestamp (ms)').sum()\n",
    "                elif os.path.basename(path).startswith('elec'):\n",
    "                    tt = tt.resample('1ms', on='Timestamp (ms)').sum()\n",
    "\n",
    "                ts =  [t.value // 10 ** 6 for t in tt.index]\n",
    "                tt.insert(0, 'Timestamp (ms)', ts)       \n",
    "                act1_df = tt.reset_index(drop=True)\n",
    "\n",
    "            # ... and rename them to allow Matlab importation\n",
    "            act1_df = act1_df.rename(columns={'Timestamp (ms)': 'TimestampMS',\n",
    "                                              'Accel X (g)': 'AccelX', \n",
    "                                              'Accel Y (g)': 'AccelY', \n",
    "                                              'Accel Z (g)': 'AccelZ', \n",
    "                                              'Sample (V)': 'SampleVolts',\n",
    "                                              'Gyro X (' + chr(176) +'/s)': 'GyroX',\n",
    "                                              'Gyro Y (' + chr(176) +'/s)': 'GyroY',\n",
    "                                              'Gyro Z (' + chr(176) +'/s)': 'GyroZ'})\n",
    "\n",
    "            # Here we transfer the data (act1_df in dataframe form) to a dictionary to allow for nested exportation to .mat file\n",
    "            trialNumStr = 'S' + str(triCount)\n",
    "            triCount += 1\n",
    "            if pd.isnull(activityAnnotationSet.iloc[trials,3]):\n",
    "                fild_df[trialNumStr] = act1_df.to_dict('split')\n",
    "            else:\n",
    "                info = activityAnnotationSet.iloc[trials,3][:25] + (activityAnnotationSet.iloc[trials,3][25:] and '_Tr')\n",
    "                newActNum = info + '_' + 'S' + str(occOfTrials[activityAnnotationSet.iloc[trials,3]] - occOfTrialsTBD[activityAnnotationSet.iloc[trials,3]] + 1)\n",
    "                occOfTrialsTBD[activityAnnotationSet.iloc[trials,3]] = occOfTrialsTBD[activityAnnotationSet.iloc[trials,3]]-1\n",
    "\n",
    "                # Gather all the data in the filled dataframe under its respective activityname   \n",
    "                fild_df[newActNum] = act1_df.to_dict('split')\n",
    "\n",
    "        activityData[activityName] = fild_df\n",
    "    \n",
    "    return activityData "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract all datafiles (accel/gyro/elec) in the subfolders of the current subject directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-04T21:48:51.319929Z",
     "start_time": "2019-06-04T21:48:51.064929Z"
    }
   },
   "outputs": [],
   "source": [
    "def extractPatientData(path, activitySet):\n",
    "    # Preallocate dictionary for sliced datafiles (accel/gyro/elec) that contain data on timestamps where \n",
    "    # activities of annotation files were performed\n",
    "    activityData = {}\n",
    "    \n",
    "    # Perform recursive iteration until .csv file is found\n",
    "    if os.path.isdir(path):\n",
    "        for name in os.listdir(path):\n",
    "            nameR = name\n",
    "            if nameR.startswith('2017') or nameR.startswith('2018'):\n",
    "                nameR = nameR[:16]\n",
    "            tbd = extractPatientData(os.path.join(path, name), activitySet)\n",
    "            if nameR in activityData:\n",
    "                activityData[nameR].update(tbd)\n",
    "            else:\n",
    "                activityData[nameR] = tbd\n",
    "    \n",
    "    # When .csv file is found (except for the annotations file), fille dictionary with activity data\n",
    "    elif os.path.isfile(path) and os.path.split(path)[1] != 'annotations.csv':\n",
    "        activityData = pd.DataFrame();\n",
    "        # Read annotations files that are present in this directory and slice datafiles (accel/gyro/elec) to contain the\n",
    "        # data on only the timestamps where activities of annotation files were performed. \n",
    "        '''\n",
    "        !!! Note that the following readAnnotationsFile function is delayed (ddel). This means that the output of this function\n",
    "        !!! is not immediately calculated, but instead saved as a delayed function. The entire combination of all datafiles/events\n",
    "        !!! will be called as a parallel computing task in a following function in the 'Run-all' section of the scripts\n",
    "        '''\n",
    "        t_df = ddel(readAnnotationsFile)(path, activitySet)\n",
    "        activityData = t_df\n",
    "    else:\n",
    "        activityData = ''\n",
    "    return activityData\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute all delayed processes that are nested in the subject data variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-04T21:48:51.487986Z",
     "start_time": "2019-06-04T21:48:51.321953Z"
    }
   },
   "outputs": [],
   "source": [
    "def subjectDataCompute(subjectDataDelayed):\n",
    "    # Preallocate a list for saving all the delayed data\n",
    "    delayedDataMat = []\n",
    "    \n",
    "    # Iterate over the delayed subject data and extract all the delayed data into a list. Afterwards compute the list to start\n",
    "    # parralel computation over all the list entries to drastically reduce computation time.\n",
    "    # (We don't use recursive functions here for debugging purposes)\n",
    "    for key,val in subjectDataDelayed.items():\n",
    "        tbd = subjectDataDelayed.copy()\n",
    "        tbd2 = tbd.pop(key)\n",
    "        for key2,val2 in tbd2.items():\n",
    "            tbd3 = tbd2.copy()\n",
    "            tbd4 = tbd3.pop(key2)\n",
    "            for key3,val3 in tbd4.items():\n",
    "                tbd5 = tbd4.copy()\n",
    "                tbd6 = tbd5.pop(key3)\n",
    "                for key4,val4 in tbd6.items():\n",
    "                    tbd7 = tbd6.copy()\n",
    "                    tbd8 = tbd7.pop(key4)\n",
    "                    delayedDataMat.append(tbd8)\n",
    "    \n",
    "    # Here we call the compute function to compute all the delayed datafiles in the delayedDataMat in a parallel fashion\n",
    "    subjectDataComputed = dask.compute(*delayedDataMat)\n",
    "#     subjectDataComputed = delayedDataMat\n",
    "    return subjectDataComputed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine computed data with a dictonary to create an orderly datastructure similar to the patient folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-04T21:48:51.633228Z",
     "start_time": "2019-06-04T21:48:51.488936Z"
    }
   },
   "outputs": [],
   "source": [
    "def combineSubjectData(subjectDataDelayed, computedData, currentSubject):\n",
    "    # Preallocate variables to fill up later\n",
    "    combinedSubjectData = {}\n",
    "    combinedSubjectData[currentSubject] = {}        \n",
    "    count = 0\n",
    "    countA = 1; countE = 1; countG = 1\n",
    "\n",
    "    # Iterate over all the keys in the delayed(!) data structure and use these as the initial dictionary structure\n",
    "    for key,val in subjectDataDelayed.items():\n",
    "        tbd = subjectDataDelayed.copy()\n",
    "        tbd2 = tbd.pop(key)\n",
    "        for key2,val2 in tbd2.items():\n",
    "            tbd3 = tbd2.copy()\n",
    "            tbd4 = tbd3.pop(key2)\n",
    "            for key3,val3 in tbd4.items():\n",
    "                # Remove all unnecessary string from the date key after you find the 'T'                \n",
    "                fk = key3.find('T')\n",
    "                key3n = key3.replace(key3[fk:], '', 1)\n",
    "                \n",
    "                # Preallocate dictionary structure with restructured order (key3 THEN key 1)\n",
    "                if key3n in combinedSubjectData[currentSubject]:\n",
    "                    pass\n",
    "                else:\n",
    "                    combinedSubjectData[currentSubject][key3n] = {}\n",
    "                if key in combinedSubjectData[currentSubject][key3n]:\n",
    "                    pass\n",
    "                else:\n",
    "                    combinedSubjectData[currentSubject][key3n][key] = {}\n",
    "                    \n",
    "                tbd5 = tbd4.copy()\n",
    "                tbd6 = tbd5.pop(key3)\n",
    "                for key4,val4 in tbd6.items():\n",
    "                    # Sometimes (errors etc.) multiple datafiles are present in the current subject sensor folders. If there\n",
    "                    # are multiple, we index them by plopping a number on them\n",
    "                    if key4.startswith('accel'):\n",
    "                        key4n = key4 + str(countA)\n",
    "                        countA += 1\n",
    "                    elif key4.startswith('elec'):\n",
    "                        key4n = key4 + str(countE)\n",
    "                        countE += 1\n",
    "                    elif key4.startswith('gyro'):\n",
    "                        key4n = key4 + str(countG)\n",
    "                        countG += 1\n",
    "                    else:\n",
    "                        key4n = key4\n",
    "                    \n",
    "                    # Combine computed data (computedData) with dictionary (combinedSubjectData). Reordering of keys can be done\n",
    "                    # here, however it is advised to do this in the following function files\n",
    "                    combinedSubjectData[currentSubject][key3n][key][key4n] = {}\n",
    "                    combinedSubjectData[currentSubject][key3n][key][key4n] = computedData[count]\n",
    "                    count += 1\n",
    "\n",
    "    return combinedSubjectData\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace string indexes that are not support by Matlab variable syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-04T21:48:51.751841Z",
     "start_time": "2019-06-04T21:48:51.634227Z"
    }
   },
   "outputs": [],
   "source": [
    "def pizza(d, oldK, newK):\n",
    "    # Pizza?\n",
    "    new = {}\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, dict):\n",
    "            v = pizza(v, oldK, newK)\n",
    "        new[k.replace(oldK, newK)] = v\n",
    "    # Pizza!\n",
    "    return new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change output order for readability and logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-04T21:48:51.880169Z",
     "start_time": "2019-06-04T21:48:51.752838Z"
    }
   },
   "outputs": [],
   "source": [
    "def alterDictionaryStructure(data):   \n",
    "    # Preallocate some variables\n",
    "    eatYourData = {}\n",
    "    \n",
    "    # Iterate over the keys that were created in the combined subjectdata variable. \n",
    "    # (No recursion for debugging purposes)\n",
    "    for key,val in data.items():\n",
    "            if key in eatYourData:\n",
    "                pass\n",
    "            else:\n",
    "                eatYourData[key] = {}\n",
    "            tbd = data.copy()\n",
    "            tbd2 = tbd.pop(key)\n",
    "            for key2,val2 in tbd2.items():\n",
    "                if key2 in eatYourData[key]:\n",
    "                    pass\n",
    "                else:\n",
    "                    eatYourData[key][key2] = {}\n",
    "                tbd3 = tbd2.copy()\n",
    "                tbd4 = tbd3.pop(key2)\n",
    "                for key3,val3 in tbd4.items():\n",
    "                    tbd5 = tbd4.copy()\n",
    "                    tbd6 = tbd5.pop(key3)\n",
    "                    for key4,val4 in tbd6.items():\n",
    "                        tbd7 = tbd6.copy()\n",
    "                        tbd8 = tbd7.pop(key4)\n",
    "                        for key5,val5 in tbd8.items():\n",
    "                            if key5 in eatYourData[key][key2]:\n",
    "                                pass\n",
    "                            else:\n",
    "                                eatYourData[key][key2][key5] = {}\n",
    "                            if key3 in eatYourData[key][key2][key5]:\n",
    "                                pass\n",
    "                            else:\n",
    "                                eatYourData[key][key2][key5][key3] = {}\n",
    "                            tbd9 = tbd8.copy()\n",
    "                            tbd10 = tbd9.pop(key5)\n",
    "                            for key6,val6 in tbd10.items():\n",
    "                                if key6 in eatYourData[key][key2][key5][key3]:\n",
    "                                    pass\n",
    "                                else:\n",
    "                                    eatYourData[key][key2][key5][key3][key6] = {}\n",
    "                                tbd11 = tbd10.copy()\n",
    "                                tbd12 = tbd11.pop(key6)\n",
    "                                eatYourData[key][key2][key5][key3][key6][key4] = tbd12       \n",
    "\n",
    "    # # Alter data key names to enable saving to .mat file\n",
    "    test = pizza(eatYourData, '.', '')\n",
    "    test = pizza(test, '-', '_')\n",
    "    test = pizza(test, '2017', 'ymd2017')\n",
    "    test = pizza(test, '2018', 'ymd2018')\n",
    "    test = pizza(test, ' ', '_')\n",
    "    test = pizza(test, '___', '_')\n",
    "    finalizedData = pizza(test, '/', '_')\n",
    "    \n",
    "    return finalizedData\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -----------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-04T21:48:52.035592Z",
     "start_time": "2019-06-04T21:48:51.883091Z"
    }
   },
   "outputs": [],
   "source": [
    "def alles(currentSubject, activitySet, currentPath):\n",
    "    # Extract all data for the current subject, using the allocated activitySet resulting in dictionary of delayed datasets\n",
    "    '''\n",
    "    !!! Note that the delayed datasets will be computed during the following function calls\n",
    "    '''\n",
    "    subjectDataDelayed = extractPatientData(currentSubjectDirectory, activitySet)\n",
    "    \n",
    "    # Since an annotations file is present in the current subject folder, we pop this key form the subjectData dictionary as it\n",
    "    # does not contain any useable subject data\n",
    "    list_keys = list(subjectDataDelayed.keys())\n",
    "    for k in list_keys:\n",
    "        if k.startswith('anno'):\n",
    "            subjectDataDelayed.pop(k)\n",
    "    \n",
    "    # Compute all delayed data using parralel computing\n",
    "    subjectDataComputed = subjectDataCompute(subjectDataDelayed)\n",
    "    \n",
    "    # Combine the computed subject data with a dictionary structure resembling the patient folder structure\n",
    "    combinedSubjectData = combineSubjectData(subjectDataDelayed, subjectDataComputed, currentSubject)\n",
    "\n",
    "    # Delete annotations file key and unnecessary nested keys from the main data dictionary\n",
    "    finalizedData = alterDictionaryStructure(combinedSubjectData)\n",
    "    \n",
    "    return finalizedData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in main subject folder to select feasible subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-04T21:48:52.155044Z",
     "start_time": "2019-06-04T21:48:52.039589Z"
    }
   },
   "outputs": [],
   "source": [
    "def select_subjects(mainPatientPath):\n",
    "    \n",
    "    # Preallocate subjectlist\n",
    "    subjectDirectoryList = []\n",
    "    \n",
    "    # Iterate over items in given main patient path, and detect feasible subject folders\n",
    "    for item in os.listdir(mainPatientPath):\n",
    "        if item.startswith('CVA'):\n",
    "            subjectDirectoryList.append(os.path.join(mainPatientPath,item))\n",
    "\n",
    "    # Here we control the amount of subjects that are saved in the subjectDirectoryList. Might be useful for when only 1 or a\n",
    "    # different specific amount of subjects are required\n",
    "    subjectDirectoryList = subjectDirectoryList[:]\n",
    "    \n",
    "    return subjectDirectoryList\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-05T10:06:07.926248Z",
     "start_time": "2019-06-04T21:48:52.161020Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301.4773745536804\n",
      "832.9558396339417\n",
      "1566.6116697788239\n",
      "2427.9288618564606\n",
      "3277.4456951618195\n",
      "4225.244484901428\n",
      "5127.347537755966\n",
      "6691.046915531158\n",
      "7163.828056335449\n",
      "8114.142024517059\n",
      "9015.752526044846\n",
      "9826.661342382431\n",
      "10853.004443407059\n",
      "11571.08915734291\n",
      "12485.365584135056\n",
      "13179.00894498825\n",
      "13459.963686227798\n",
      "14259.696521520615\n",
      "15132.057679891586\n",
      "15661.951844930649\n",
      "16928.71837568283\n",
      "18028.078919410706\n",
      "18607.29796743393\n",
      "19357.56440114975\n",
      "20421.238462924957\n",
      "21309.599083185196\n",
      "22725.11762857437\n",
      "23657.305287599564\n",
      "24393.852690935135\n",
      "25548.644151210785\n",
      "26590.840001821518\n",
      "27434.340468406677\n",
      "28352.76505923271\n",
      "29050.01438856125\n",
      "29833.47002840042\n",
      "30548.427880048752\n",
      "31406.38359761238\n",
      "31965.463836669922\n",
      "32586.05991244316\n",
      "33270.90717935562\n",
      "33872.75172305107\n",
      "34771.50609755516\n",
      "35724.73108148575\n",
      "36278.5560092926\n",
      "37083.41713500023\n",
      "37724.32567238808\n",
      "38454.20196557045\n",
      "39140.09416246414\n",
      "39908.74111032486\n",
      "40541.23784446716\n",
      "41628.25576996803\n",
      "42357.74273991585\n",
      "43101.46178007126\n",
      "43735.85276436806\n",
      "44235.61945962906\n"
     ]
    }
   ],
   "source": [
    "# Select main subject directory to detect feasible patient folders\n",
    "subjectDirectoryList = select_subjects(r'//FS2.smpp.local\\RTO\\Inpatient Sensors -Stroke\\MC10 Study\\Data\\biostamp_data\\cva')\n",
    "\n",
    "s = time.time()\n",
    "# Allocating the activities that are to be extracted. Can remove/ add to current list (allbut PT)\n",
    "activitySet = [\n",
    "        'Resting ECG'\n",
    "              ]\n",
    "\n",
    "# Iterate over all subjects in the subjectDirectoryList and extract their data\n",
    "for currentSubjectDirectory in subjectDirectoryList:\n",
    "    \n",
    "    # Allocating the current subject name\n",
    "    currentSubject = os.path.basename(currentSubjectDirectory)\n",
    "\n",
    "#     activitySet = ['Clinical - 10MWT SSV']\n",
    "    global currentPath\n",
    "    currentPath = currentSubjectDirectory\n",
    "\n",
    "    # Extract all data for the current subject, using the allocated activitySet resulting in dictionary of delayed datasets\n",
    "    '''\n",
    "    !!! Note that the delayed datasets will be computed during the following function calls\n",
    "    '''\n",
    "    subjectDataDelayed = extractPatientData(currentSubjectDirectory, activitySet)\n",
    "    \n",
    "    # Since an annotations file is present in the current subject folder, we pop this key form the subjectData dictionary as it\n",
    "    # does not contain any useable subject data\n",
    "    list_keys = list(subjectDataDelayed.keys())\n",
    "    for k in list_keys:\n",
    "        if k.startswith('anno'):\n",
    "            subjectDataDelayed.pop(k)\n",
    "    \n",
    "    # Compute all delayed data using parralel computing\n",
    "    subjectDataComputed = subjectDataCompute(subjectDataDelayed)\n",
    "    \n",
    "    # Combine the computed subject data with a dictionary structure resembling the patient folder structure\n",
    "    combinedSubjectData = combineSubjectData(subjectDataDelayed, subjectDataComputed, currentSubject)\n",
    "\n",
    "    # Delete annotations file key and unnecessary nested keys from the main data dictionary\n",
    "    finalizedData = alterDictionaryStructure(combinedSubjectData)\n",
    "     \n",
    "    \n",
    "    \n",
    "#     # Initiate a global variable for the current subjectpath, making a copy to be used in all functions\n",
    "#     finalizedData = alles(currentSubject, activitySet, currentPath)\n",
    "\n",
    "    # Save mats per activity\n",
    "    sio.savemat(currentSubject, finalizedData, oned_as = 'column')\n",
    "\n",
    "    subjectDataDelayed = None\n",
    "    subjectDataComputed = None\n",
    "    combinedSubjectData = None\n",
    "    finalizedData = None\n",
    "\n",
    "    e = time.time()\n",
    "    print(e-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
